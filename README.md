# Multi-Robot Testbed Platform

[![Python Version](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Platform](https://img.shields.io/badge/platform-linux%20%7C%20windows-lightgrey.svg)](https://github.com/yourusername/testbed)

> [ğŸ‡ªğŸ‡¸ VersiÃ³n en EspaÃ±ol](#versiÃ³n-en-espaÃ±ol) | [ğŸ‡¬ğŸ‡§ English Version](#english-version)

---

## ğŸ‡¬ğŸ‡§ English Version

A comprehensive Python framework for simulating and deploying multi-robot control systems with real-time vision tracking using ArUco markers.

### ğŸ¯ Features

- **ğŸ¤– Dual Operation Modes**: Virtual simulation and real hardware implementation
- **ğŸ‘ï¸ Vision-Based Tracking**: Real-time pose estimation using ArUco markers and OpenCV
- **ğŸ® Multiple Controllers**: PID, reactive, and CLF-based control strategies
- **ğŸ›¡ï¸ Safety Mechanisms**: Barrier certificates for collision avoidance
- **ğŸ“Š Multi-Robot Support**: Control up to 30 robots simultaneously
- **ğŸ“ˆ Trajectory Tracking**: Load and follow predefined paths from MATLAB data
- **ğŸ¥ Video Recording**: Built-in capability to record experiments

### ğŸ“‹ Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Hardware Setup](#hardware-setup)
- [Configuration](#configuration)
- [Usage Examples](#usage-examples)
- [Project Structure](#project-structure)
- [Controllers](#available-controllers)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [Citation](#citation)

---

## ğŸš€ Installation

### Prerequisites

- **Software**:
  - Python 3.10 or higher
  - pip package manager
  - Git

- **Hardware** (for real experiments):
  - USB camera (webcam or external)
  - ESP8266 WiFi modules (for robot communication)
  - ArUco markers (4x4_100 dictionary, 10.2cm size)
  - Mobile robots with differential drive

### Setup Steps

1. **Clone the repository**:
```bash
git clone https://github.com/yourusername/testbed.git
cd testbed
```

2. **Create a virtual environment**:
```bash
# Linux/Mac
python3 -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

3. **Install dependencies**:
```bash
pip install -r requirements.txt
```

4. **Install as a package** (optional):
```bash
pip install -e .
```

---

## ğŸ® Quick Start

### Virtual Simulation

```python
from testbed_virt import Testbed
import utilities.controllers as ctrl
import utilities.misc as misc
import numpy as np

# Initialize testbed with 3 robots
N = 3
initial_conditions = misc.generate_initial_conditions(N)
testbed = Testbed(
    number_of_robots=N,
    show_figure=True,
    initial_conditions=initial_conditions
)

# Create PID controller
controller = ctrl.create_pid_unicycle_pose_controller(
    linear_gain=[10, 0.1, 0.2],
    angular_gain=[14, 0.1, 0.5],
    num_robots=N
)

# Define goal positions
goals = np.array([[100, -100, 0], 
                  [50, -50, 0], 
                  [np.pi/2, -np.pi/2, 0]])

# Control loop
for _ in range(500):
    x = testbed.get_poses()
    dxu = controller(x, goals)
    testbed.set_velocities(np.arange(N), dxu)
    testbed.step()

testbed.call_at_scripts_end()
```

### Real Hardware

```python
from testbed_real import Testbed

# Same code as above, but uses real robots!
testbed = Testbed(
    number_of_robots=3,
    show_figure=True,
    initial_conditions=initial_conditions
)

# Enable video recording
testbed.record_video('my_experiment')

# ... control loop
```

---

## ğŸ”§ Hardware Setup

### Camera Configuration

The camera ID can be configured in `testbed_real.py` (line 81):

```python
self.cap = cv2.VideoCapture(0)  # Camera selection
```

**Camera IDs**:
- `0`: Built-in/front camera
- `1`: External/back camera  
- `2`: Secondary external camera

### Serial Communication

Configure serial ports for ESP8266 communication:

#### Windows
```python
# In testbed_real.py (lines 105-108)
self.esp8266 = serial.Serial("COM4", 115200)
if number_of_robots > 6:
    self.esp8266_2 = serial.Serial("COM5", 115200)
```

#### Linux/Ubuntu
```python
self.esp8266 = serial.Serial("/dev/ttyUSB0", 115200)
if number_of_robots > 6:
    self.esp8266_2 = serial.Serial("/dev/ttyUSB1", 115200)
```

**Note**: For more than 6 robots, you need to connect a second antenna.

#### Grant Serial Port Permissions (Linux)
```bash
sudo chmod 666 /dev/ttyUSB0
# Or permanently:
sudo usermod -a -G dialout $USER
# Then logout and login
```

---

## âš™ï¸ Configuration

### Camera Calibration

1. Place calibration files in the `Camera/` directory:
   - `cameraMatrix.txt`: Camera intrinsic matrix
   - `cameraDistortion.txt`: Distortion coefficients

2. Generate calibration using OpenCV calibration tools or provided scripts.

### Robot Parameters

Edit in `testbed_real.py` or `testbed_virt.py`:

```python
self.robot_diameter = 20      # cm
self.wheel_radius = 3         # cm
self.base_length = 11         # cm
self.max_linear_velocity = 300   # units/s
self.max_angular_velocity = 45   # rad/s
```

### Arena Boundaries

```python
self.boundaries = [-200, -150, 200, 150]  # [x_min, y_min, x_max, y_max]
```

---

## ğŸ“š Usage Examples

### 1. Load Trajectory Data

Modify `utilities/misc.py` to load your data format:

```python
# Load MATLAB data
load_position = misc.load_data_matlab(
    'data/my_trajectory.mat',
    split_data=10,
    shift_x=0,
    scale_x=1
)

# Use in control loop
for i in range(num_steps):
    goal_points = load_position(i)[:, :N]
    # ... control logic
```

### 2. Create Custom Controller

Add to `utilities/controllers.py`:

```python
def create_my_controller(gain=1.0, num_robots=1):
    """My custom controller."""
    def controller(states, goals):
        # Your control law
        velocities = compute_control(states, goals, gain)
        return velocities
    return controller
```

### 3. Enable Safety Barriers

```python
from utilities.barrier_certificates import (
    create_unicycle_barrier_certificate_with_boundary
)

# Create barrier certificate
barrier = create_unicycle_barrier_certificate_with_boundary(
    barrier_gain=100,
    safety_radius=17,
    boundary_points=np.array([-200, 200, -150, 150])
)

# Apply in control loop
dxu = controller(x, goals)
dxu_safe = barrier(dxu, x)  # Safe velocities
testbed.set_velocities(np.arange(N), dxu_safe)
```

### 4. Record Video

```python
# Start recording
testbed.record_video('experiment_name')

# Control loop...

# Video automatically saved in Videos/ folder
testbed.call_at_scripts_end()
```

---

## ğŸ“ Project Structure

```
Testbed/
â”œâ”€â”€ testbed_real.py         # Real hardware implementation
â”œâ”€â”€ testbed_virt.py         # Virtual simulation
â”œâ”€â”€ testbed.py              # Base class (ABC)
â”œâ”€â”€ plotlab.py              # Visualization tools
â”‚
â”œâ”€â”€ utilities/              # Control & vision utilities
â”‚   â”œâ”€â”€ controllers.py      # Control algorithms
â”‚   â”œâ”€â”€ barrier_certificates.py  # Safety mechanisms
â”‚   â”œâ”€â”€ misc.py            # Helper functions
â”‚   â”œâ”€â”€ transformations.py # Coordinate transforms
â”‚   â””â”€â”€ ArucoModule.py     # Computer vision
â”‚
â”œâ”€â”€ Camera/                 # Camera calibration
â”‚   â”œâ”€â”€ cameraMatrix.txt
â”‚   â””â”€â”€ cameraDistortion.txt
â”‚
â”œâ”€â”€ Markers/                # ArUco marker images
â”œâ”€â”€ data/                   # Experimental data (.mat, .csv)
â”œâ”€â”€ Videos/                 # Recorded videos
â”‚
â”œâ”€â”€ examples/               # Example scripts
â”‚   â”œâ”€â”€ thesis_example.py
â”‚   â”œâ”€â”€ control_example.py
â”‚   â”œâ”€â”€ tune_pid.py
â”‚   â””â”€â”€ tune_pid_regression.py
â”‚
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

---

## ğŸ›ï¸ Available Controllers

### 1. PID Position Controller
```python
controller = ctrl.create_pid_unicycle_position_controller(
    linear_gain=[kp, ki, kd],
    angular_gain=[kp, ki, kd],
    num_robots=N
)
```

### 2. PID Pose Controller
```python
controller = ctrl.create_pid_unicycle_pose_controller(
    linear_gain=[10, 0.1, 0.2],
    angular_gain=[14, 0.1, 0.5],
    num_robots=N
)
```

### 3. Reactive Pose Controller (Collision Avoidance)
```python
controller = ctrl.create_reactive_pose_controller(
    linear_gain=[9, 0.1, 0],
    angular_gain=[14, 0.1, 1],
    num_robots=N
)
```

### 4. CLF-Based Controllers
- `create_clf_unicycle_position_controller`
- `create_clf_unicycle_pose_controller`
- `create_hybrid_unicycle_pose_controller`

---

## ğŸ› Troubleshooting

### Camera Not Detected
```bash
# List available cameras
ls /dev/video*

# Test camera
python -c "import cv2; print(cv2.VideoCapture(0).isOpened())"
```

### Serial Port Access Denied (Linux)
```bash
# Check permissions
ls -l /dev/ttyUSB0

# Add user to dialout group
sudo usermod -a -G dialout $USER
# Logout and login

# Or temporary fix
sudo chmod 666 /dev/ttyUSB0
```

### ArUco Markers Not Detected
- Ensure proper lighting (avoid shadows)
- Check marker size matches configuration (10.2cm)
- Verify camera calibration files
- Clean marker surfaces

### Import Errors
```bash
# Reinstall dependencies
pip install --force-reinstall -r requirements.txt

# Check Python version
python --version  # Should be 3.10+
```

---

## ğŸ§ª Testing

Run example scripts to verify installation:

```bash
# Virtual simulation
python thesis_example.py

# PID tuning (generates heatmap)
python tune_pid.py

# Control example
python control_example.py
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Code Style
- Follow PEP 8 guidelines
- Add docstrings to functions
- Include type hints where possible
- Write descriptive commit messages

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“ Citation

If you use this testbed in your research, please cite:

```bibtex
@software{testbed2024,
  title={Multi-Robot Testbed Platform},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/testbed},
  version={1.0}
}
```

---

## ğŸ™ Acknowledgments

- Based on the [Robotarium](https://www.robotarium.gatech.edu/) framework
- Uses [OpenCV](https://opencv.org/) for computer vision
- ArUco marker detection via opencv-contrib
- Barrier certificates adapted from [Georgia Tech GRITS Lab](https://www.davidanisi.com/)

---

## ğŸ“§ Contact & Support

- **Author**: Your Name
- **Email**: your.email@example.com
- **Issues**: [GitHub Issues](https://github.com/yourusername/testbed/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/testbed/discussions)

---

## ğŸ›£ï¸ Roadmap

- [ ] ROS2 integration
- [ ] Web-based visualization dashboard
- [ ] Automatic camera calibration tool
- [ ] Docker containerization
- [ ] Real-time telemetry dashboard
- [ ] Multi-camera support
- [ ] Gazebo simulation integration

---

## ğŸ“Š System Requirements

### Minimum
- CPU: Dual-core 2.0 GHz
- RAM: 4 GB
- Camera: 640x480 @ 30fps
- OS: Ubuntu 20.04+, Windows 10+

### Recommended  
- CPU: Quad-core 2.5 GHz+
- RAM: 8 GB+
- Camera: 1920x1080 @ 60fps
- GPU: Optional (for advanced visualization)
- OS: Ubuntu 22.04

---

<p align="center">
  Made with â¤ï¸ for robotics research
</p>

---
---
---

# ğŸ‡ªğŸ‡¸ VersiÃ³n en EspaÃ±ol

## Plataforma Testbed Multi-Robot

Framework completo en Python para simular y desplegar sistemas de control multi-robot con seguimiento visual en tiempo real usando marcadores ArUco.

### ğŸ¯ CaracterÃ­sticas

- **ğŸ¤– Modos de OperaciÃ³n Duales**: SimulaciÃ³n virtual e implementaciÃ³n en hardware real
- **ğŸ‘ï¸ Seguimiento Basado en VisiÃ³n**: EstimaciÃ³n de pose en tiempo real usando marcadores ArUco y OpenCV
- **ğŸ® MÃºltiples Controladores**: Estrategias de control PID, reactivo y basado en CLF
- **ğŸ›¡ï¸ Mecanismos de Seguridad**: Certificados de barrera para evitar colisiones
- **ğŸ“Š Soporte Multi-Robot**: Controla hasta 30 robots simultÃ¡neamente
- **ğŸ“ˆ Seguimiento de Trayectorias**: Carga y sigue trayectorias predefinidas desde datos MATLAB
- **ğŸ¥ GrabaciÃ³n de Video**: Capacidad integrada para grabar experimentos

---

## ğŸš€ InstalaciÃ³n

### Requisitos Previos

- **Software**:
  - Python 3.10 o superior
  - Gestor de paquetes pip
  - Git

- **Hardware** (para experimentos reales):
  - CÃ¡mara USB (webcam o externa)
  - MÃ³dulos WiFi ESP8266 (para comunicaciÃ³n con robots)
  - Marcadores ArUco (diccionario 4x4_100, tamaÃ±o 10.2cm)
  - Robots mÃ³viles con tracciÃ³n diferencial

### Pasos de ConfiguraciÃ³n

1. **Clonar el repositorio**:
```bash
git clone https://github.com/tuusuario/testbed.git
cd testbed
```

2. **Crear entorno virtual**:
```bash
# Linux/Mac
python3 -m venv venv
source venv/bin/activate

# Windows
python -m venv venv
venv\Scripts\activate
```

3. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

4. **Instalar como paquete** (opcional):
```bash
pip install -e .
```

---

## ğŸ® Inicio RÃ¡pido

### SimulaciÃ³n Virtual

```python
from testbed_virt import Testbed
import utilities.controllers as ctrl
import utilities.misc as misc
import numpy as np

# Inicializar testbed con 3 robots
N = 3
condiciones_iniciales = misc.generate_initial_conditions(N)
testbed = Testbed(
    number_of_robots=N,
    show_figure=True,
    initial_conditions=condiciones_iniciales
)

# Crear controlador PID
controlador = ctrl.create_pid_unicycle_pose_controller(
    linear_gain=[10, 0.1, 0.2],
    angular_gain=[14, 0.1, 0.5],
    num_robots=N
)

# Definir posiciones objetivo
metas = np.array([[100, -100, 0], 
                  [50, -50, 0], 
                  [np.pi/2, -np.pi/2, 0]])

# Lazo de control
for _ in range(500):
    x = testbed.get_poses()
    dxu = controlador(x, metas)
    testbed.set_velocities(np.arange(N), dxu)
    testbed.step()

testbed.call_at_scripts_end()
```

---

## ğŸ”§ ConfiguraciÃ³n de Hardware

### ConfiguraciÃ³n de CÃ¡mara

El ID de cÃ¡mara se configura en `testbed_real.py` (lÃ­nea 81):

```python
self.cap = cv2.VideoCapture(0)  # SelecciÃ³n de cÃ¡mara
```

**IDs de CÃ¡mara**:
- `0`: CÃ¡mara integrada/frontal
- `1`: CÃ¡mara externa/trasera
- `2`: CÃ¡mara externa secundaria

### ComunicaciÃ³n Serial

Configurar puertos seriales para comunicaciÃ³n ESP8266:

#### Windows
```python
# En testbed_real.py (lÃ­neas 105-108)
self.esp8266 = serial.Serial("COM4", 115200)
if number_of_robots > 6:
    self.esp8266_2 = serial.Serial("COM5", 115200)
```

#### Linux/Ubuntu
```python
self.esp8266 = serial.Serial("/dev/ttyUSB0", 115200)
if number_of_robots > 6:
    self.esp8266_2 = serial.Serial("/dev/ttyUSB1", 115200)
```

**Nota**: Para mÃ¡s de 6 robots, necesitas conectar una segunda antena.

#### Otorgar Permisos de Puerto Serial (Linux)
```bash
sudo chmod 666 /dev/ttyUSB0
# O permanentemente:
sudo usermod -a -G dialout $USER
# Luego cerrar sesiÃ³n e iniciar nuevamente
```

---

## âš™ï¸ ConfiguraciÃ³n

### CalibraciÃ³n de CÃ¡mara

1. Coloca archivos de calibraciÃ³n en el directorio `Camera/`:
   - `cameraMatrix.txt`: Matriz intrÃ­nseca de cÃ¡mara
   - `cameraDistortion.txt`: Coeficientes de distorsiÃ³n

2. Genera calibraciÃ³n usando herramientas de OpenCV o scripts provistos.

### ParÃ¡metros del Robot

Editar en `testbed_real.py` o `testbed_virt.py`:

```python
self.robot_diameter = 20      # cm
self.wheel_radius = 3         # cm  
self.base_length = 11         # cm
self.max_linear_velocity = 300   # unidades/s
self.max_angular_velocity = 45   # rad/s
```

### LÃ­mites del Arena

```python
self.boundaries = [-200, -150, 200, 150]  # [x_min, y_min, x_max, y_max]
```

---

## ğŸ“š Ejemplos de Uso

### 1. Cargar Datos de Trayectoria

Modificar `utilities/misc.py` para cargar tu formato de datos:

```python
# Cargar datos MATLAB
cargar_posicion = misc.load_data_matlab(
    'data/mi_trayectoria.mat',
    split_data=10,
    shift_x=0,
    scale_x=1
)

# Usar en lazo de control
for i in range(num_pasos):
    puntos_meta = cargar_posicion(i)[:, :N]
    # ... lÃ³gica de control
```

### 2. Grabar Video

```python
# Iniciar grabaciÃ³n
testbed.record_video('nombre_experimento')

# Lazo de control...

# Video guardado automÃ¡ticamente en carpeta Videos/
testbed.call_at_scripts_end()
```

---

## ğŸ› SoluciÃ³n de Problemas

### CÃ¡mara No Detectada
```bash
# Listar cÃ¡maras disponibles
ls /dev/video*

# Probar cÃ¡mara
python -c "import cv2; print(cv2.VideoCapture(0).isOpened())"
```

### Acceso Denegado al Puerto Serial (Linux)
```bash
# Verificar permisos
ls -l /dev/ttyUSB0

# Agregar usuario al grupo dialout
sudo usermod -a -G dialout $USER
# Cerrar sesiÃ³n e iniciar nuevamente

# O soluciÃ³n temporal
sudo chmod 666 /dev/ttyUSB0
```

### Marcadores ArUco No Detectados
- Asegurar iluminaciÃ³n adecuada (evitar sombras)
- Verificar que tamaÃ±o de marcador coincide con configuraciÃ³n (10.2cm)
- Verificar archivos de calibraciÃ³n de cÃ¡mara
- Limpiar superficies de marcadores

---

## ğŸ“§ Contacto y Soporte

- **Autor**: Tu Nombre
- **Email**: tu.email@ejemplo.com
- **Problemas**: [GitHub Issues](https://github.com/tuusuario/testbed/issues)

---

<p align="center">
  Hecho con â¤ï¸ para investigaciÃ³n en robÃ³tica
</p>